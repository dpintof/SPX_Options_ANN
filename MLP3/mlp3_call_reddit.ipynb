{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["Clear the console and remove all variables present on the namespace"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["try:\n", "    from IPython import get_ipython\n", "    get_ipython().magic('clear')\n", "    get_ipython().magic('reset -f')\n", "except:\n", "    pass"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from os import path\n", "import pandas as pd\n", "from sklearn.model_selection import train_test_split\n", "from tensorflow import keras\n", "import tensorflow as tf\n", "tf.compat.v1.enable_eager_execution()\n", "from tensorflow.keras import layers, losses\n", "import numpy as np"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Hyperparameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_hidden_layers = 2 # Number of hidden layers.\n", "n_units = 128 # Number of neurons of the hidden layers.\n", "n_batch = 64 # Number of observations used per gradient update.\n", "n_epochs = 30"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create DataFrame (df) with random floats"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["call_df = pd.DataFrame(np.random.rand(6000000, 6) * 100, \n", "                       columns=['Strike', \"Time to Maturity\", \n", "                                \"Option_Average_Price\", \"RF Rate\", \n", "                                \"Sigma 20 Days Annualized\", \n", "                                \"Underlying Price\"])\n", "# call_df = call_df.iloc[-10:,:]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split call_df into random train and test subsets, for inputs (X) and output (y)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["call_X_train, call_X_test, call_y_train, call_y_test = (train_test_split(\n", "    call_df.drop([\"Option_Average_Price\"], axis = 1), \n", "    call_df.Option_Average_Price, test_size = 0.01))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create model using Keras' Functional API"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def mlp3_call(n_hidden_layers, n_units):\n", "    # Create input layer\n", "    inputs = keras.Input(shape = (call_X_train.shape[1],))\n", "    x = layers.LeakyReLU(alpha = 1)(inputs)\n\n", "    # Create hidden layers\n", "    for _ in range(n_hidden_layers):\n", "        x = hl(x, n_units)\n\n", "    # Create output layer\n", "    outputs = layers.Dense(1, activation = keras.activations.softplus)(x)\n\n", "    # Actually create the model\n", "    model = keras.Model(inputs=inputs, outputs=outputs)\n", "    \n", "    return model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Hidden layer generation function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def hl(tensor, n_units):\n", "    hl_output = layers.Dense(n_units, \n", "                             activation = layers.LeakyReLU(alpha=1))(tensor)\n", "    return hl_output"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Custom loss function that is a MSE function plus three soft constraints"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def constrained_mse(y_true, y_pred):\n", "    \n", "    mse = losses.mse(y_true, y_pred)\n", "    \n", "    x = tf.convert_to_tensor(call_X_train, np.float32)\n", "    \n", "    with tf.GradientTape() as tape:\n", "        tape.watch(x)\n", "        with tf.GradientTape() as tape2:\n", "            tape2.watch(x)\n", "            y = model(x)\n", "        \n", "    grad_y = tape2.gradient(y, x)\n", "    dy_dstrike = grad_y[0, 0]\n", "    dy_dttm = grad_y[0, 1]\n", "    \n", "    grad_y2 = tape.gradient(y, x)\n", "    d2y_dstrike2 = grad_y2[0, 0]\n", "    \n", "    loss = mse + dy_dstrike + dy_dttm + d2y_dstrike2\n", "    return loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = mlp3_call(n_hidden_layers, n_units) \n", "model.compile(loss = constrained_mse, optimizer = keras.optimizers.Adam(),)\n", "history = model.fit(call_X_train, call_y_train, batch_size = n_batch, \n", "                    epochs = n_epochs, validation_split = 0.01, verbose = 1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Save the model's architecture, weights and optimizer's state"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["directory = path.join(\"Saved_models\", \"mlp3_call_1\")\n", "model.save(directory)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Save the model's train and validation losses for each epoch."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}